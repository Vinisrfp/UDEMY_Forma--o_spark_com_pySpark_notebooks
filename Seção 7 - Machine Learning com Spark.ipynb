{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seção 7: Machine learning com Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\\\ApacheSpark\\\\spark-3.5.3-bin-hadoop3\"\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 55. Fundamentos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oque é machine learning?\n",
    "\n",
    "- Machine Learning (ML) é um subcampo da inteligência artificial (IA) que permite que sistemas aprendam e melhorem com a experiência sem serem explicitamente programados para cada tarefa. Em vez disso, eles usam dados para treinar modelos que identificam padrões e fazem previsões ou decisões. O aprendizado ocorre por meio de algoritmos que ajustam as previsões com base nos dados de entrada e nos resultados esperados.\n",
    "\n",
    "#### Como funciona\n",
    "O ML se baseia em algoritmos que processam grandes volumes de dados para descobrir padrões. Existem diferentes tipos de aprendizado:\n",
    "\n",
    "- Supervisionado: O modelo é treinado com dados rotulados (exemplo: entrada e resposta esperada). Útil para classificação e regressão.\n",
    "- Não supervisionado: Trabalha com dados não rotulados, encontrando padrões e grupos ocultos nos dados. Aplicável para segmentação e redução de dimensionalidade.\n",
    "- Reforço: O modelo aprende por tentativa e erro, recebendo recompensas por acertos e penalidades por erros, aplicável em áreas como controle robótico e jogos.\n",
    "#### Aplicações\n",
    "Machine Learning pode ser aplicado em diversas áreas:\n",
    "\n",
    "- Financeiro: Previsão de preços, detecção de fraudes, análise de risco e algoritmos de negociação.\n",
    "- Saúde: Diagnóstico médico assistido, análise de imagem, descoberta de medicamentos e previsões de epidemias.\n",
    "- Marketing: Segmentação de clientes, recomendações personalizadas, análise de sentimentos e previsão de churn.\n",
    "- Indústria: Manutenção preditiva, otimização de processos e controle de qualidade.\n",
    "- Tecnologia: Assistentes virtuais, reconhecimento de fala, visão computacional, e recomendações de conteúdo.\n",
    "#### Principais informações\n",
    "- Dados são fundamentais: ML depende de dados de qualidade para obter bons resultados.\n",
    "- Algoritmos: Há várias técnicas, como árvores de decisão, redes neurais, regressão linear, máquinas de vetor de suporte (SVM), e mais.\n",
    "- Avaliação do Modelo: É importante validar a precisão e ajustar os parâmetros do modelo.\n",
    "- Infraestrutura: Ferramentas como Databricks, AWS, e bibliotecas como TensorFlow e Scikit-learn são comumente usadas.\n",
    "Machine Learning permite que sistemas automatizem decisões complexas, oferecendo insights que podem transformar o funcionamento de empresas, instituições e até do cotidiano.\n",
    "#### Conceitos\n",
    "- Classe: é o que se buscar prever ou classificar\n",
    "   - Ex: Espécie de planta, doença do paciente, se o cliente é bom pagador\n",
    "   - Classe também é um atributo, é uma caracteristica.\n",
    "   - Podemos ter atributos nominais ou numéricos (espécie de uma plata e comprimento).\n",
    "   ##### Classificações\n",
    "   - Classificação binária: é a classificação do objetivo em SIM ou NÃO.(Possui diferentes valores mas todas as clases estão na mesma coluna, mas possui apenas duas possibilidades).\n",
    "   - Classificação multiclasse: é quanto temos mais de duas possibilidades(Possui diferentes valores mas todas as clases estão na mesma coluna).\n",
    "   - Classificação multilabel: Se trata do conceito de classificar algo em mais de uma classe ao mesmo tempo. Ex: Uma música pode ser suave, clássica. E também pode ser uma música que não é moderna (Imaginamos que o que eu quero prever está em mais de uma coluna e uma linha pode ser classificada em mais de uma coluna ao mesmo tempo).\n",
    "- Dimensão ou atributo: são as características usadas como parâmetros para classificar\n",
    "- Instância: é uma observação\n",
    "- Relação: conjunto de dados\n",
    "#### Considerações sobre o modelo\n",
    "- Depende do Algoritmo utilizado\n",
    "- Pode perder a eficiência\n",
    "- Muito específico do negócio\n",
    "#### Regressão\n",
    "- Aplicado quando a classe é contínua\n",
    "- Exemplo: Você tem todas as informações de um carro e quer prever a potência de um motor(Será númerica)\n",
    "#### Métrica de Erros\n",
    "Quanto é necessario apurar um modelo que possui regressão(numeros reais ou inteiros) usamos outros tipos de métricas, agora não podemos mais avaliar se está certa ou errada, devemos avaliar a distancia da previsão feita com o valor que de fato ocorreu.\n",
    "##### Root Mean Squared Error (RMSE)\n",
    "Independente de Escala\n",
    " - O desvio padrão da amosta da diferença entre o previsto e o teste\n",
    "\n",
    "|Previsto    |Realizado    |Dif. ao Quad.|\n",
    "|:----------:|:-----------:|:-----------:|\n",
    "|3,34        |3,00         |0,1156       |                   \n",
    "|4,18        |4,00         |0,0324       |\n",
    "\n",
    "- Pi = Valor previsto\n",
    "- Ti = Valor realizado\n",
    "- N = Quantidade de informações\n",
    "\n",
    "RMSE =$$\\sqrt{(∑^Ni=1(Pi-Ti)^2)/N}$$   \n",
    "\n",
    "- RMSE =$$\\sqrt{0,1483/2}$$   \n",
    "- RMSE ≈ 0,2723\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 56. Machine Learning no Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas\n",
    "\n",
    " - spark.mllib\n",
    " - spark.ml\n",
    "\n",
    "ML baseado em RDD está descontinuado, agora as implementações são todas em DataFrames.\n",
    "\n",
    "#### Variáveis\n",
    "Variáveis Independentes - São colunas distintas\n",
    "Variável Dependente - Outra coluna, que normalmente é apenas uma coluna \n",
    "\n",
    "#### Variáveis No spark\n",
    "Normalmente todas as váriaveis independentes devem compor uma mesma coluna. Cria-se um vetor único, que é adicionado em uma nova coluna no Dataframe\n",
    "\n",
    "#### One HotEncoding\n",
    "- Machine Learning suporta apenas números\n",
    "- Atributos categóricos devem ser transformados em colunas, recebendo numeros para true ou false.\n",
    "\n",
    "##### One HotEnconding no spark\n",
    "- Existe o problema que se o atributo tiver muitos valores, serão criadas muitas colunas. Ex: Estados de um pais.\n",
    "- Para isso o spark permite o uso de matriz esparsa. Imagine que tivemossemos 27 estados, para cada linhas teriamos 26 zeros e apenas 1 um, a matriz esparsa compacta as matrizes que contém muitos valores 0.\n",
    "\n",
    "#### Formulas no R\n",
    "**R** permite definir o modelo através de fórmula.\n",
    "- Spark implemente Rformula\n",
    " - Aplica One HotEnconding e combina variáveis independentes em uma única coluna.\n",
    "\n",
    "#### Pipelines\n",
    "- Transformer: Transforma um DF em outro DF\n",
    "- Estimator: Fir em DF para produzier um Transformer\n",
    "- Pipeline: conecta Transformers Estimators para Produzir modelo\n",
    "- Parâmetros: Transformers e Estimators compartilham uma Api para definir parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 57. Preparando Dados para Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas| HP|\n",
      "+-------+---------+-----------+---+\n",
      "|     21|        6|        160|110|\n",
      "|     21|        6|        160|110|\n",
      "|    228|        4|        108| 93|\n",
      "|    214|        6|        258|110|\n",
      "|    187|        8|        360|175|\n",
      "+-------+---------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "#criando dataframe\n",
    "carros_tmp = spark.read.csv(r'C:\\Users\\viser\\OneDrive\\Documentos\\Cursos\\UDEMY_Formação Spark com pySpark\\Material\\files\\Carros.csv', inferSchema=True, header=True, sep=';')\n",
    "carros = carros_tmp.select('Consumo', 'Cilindros', 'Cilindradas', 'HP')\n",
    "carros.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar vetor de caracteristicas\n",
    "# inputCols - Colunas que possuem as informações que serão avaliadas (Variaveis independentes)\n",
    "# outputCol - Nome da coluna que vai receber as informações atraves de um vetor\n",
    "\n",
    "vtcaracteristicas = VectorAssembler(inputCols=[('Consumo'), ('Cilindros'), ('Cilindradas')], outputCol='caracteristicas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---+-----------------+\n",
      "|Consumo|Cilindros|Cilindradas| HP|  caracteristicas|\n",
      "+-------+---------+-----------+---+-----------------+\n",
      "|     21|        6|        160|110| [21.0,6.0,160.0]|\n",
      "|     21|        6|        160|110| [21.0,6.0,160.0]|\n",
      "|    228|        4|        108| 93|[228.0,4.0,108.0]|\n",
      "|    214|        6|        258|110|[214.0,6.0,258.0]|\n",
      "|    187|        8|        360|175|[187.0,8.0,360.0]|\n",
      "+-------+---------+-----------+---+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aplicando vetorização nos dados \n",
    "carros = vtcaracteristicas.transform(carros)\n",
    "carros.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# dividir os dados para treino do modelo e dados para teste (divisão feita em porcentagem)\n",
    "carrosTreino, CarrosTeste = carros.randomSplit([0.7,0.3])\n",
    "print(carrosTreino.count())\n",
    "print(CarrosTeste.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 58. Criando um Modelo de Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando modelo do tipo de regressão com os dados de treino\n",
    "\n",
    "# featuresCol - Coluna que foi vetorizadas com as informações (Variaveis independentes)\n",
    "# labelCol - Coluna que possui as informações verdadeiras de histórico (Variavel dependente)\n",
    "\n",
    "reglin = LinearRegression(featuresCol='caracteristicas', labelCol='HP')\n",
    "modelo = reglin.fit(carrosTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---+------------------+------------------+\n",
      "|Consumo|Cilindros|Cilindradas| HP|   caracteristicas|        prediction|\n",
      "+-------+---------+-----------+---+------------------+------------------+\n",
      "|     15|        8|        301|335|  [15.0,8.0,301.0]|192.79015322731442|\n",
      "|    104|        8|        472|205| [104.0,8.0,472.0]|196.17423250681458|\n",
      "|    133|        8|        350|245| [133.0,8.0,350.0]|197.62144504269622|\n",
      "|    155|        8|        318|150| [155.0,8.0,318.0]|198.60194185479588|\n",
      "|    164|        8|       2758|180|[164.0,8.0,2758.0]|194.24737111868768|\n",
      "+-------+---------+-----------+---+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Com o modelo criado, já podemos fazer a previsão - método transform do modelo\n",
    "previsao = modelo.transform(CarrosTeste)\n",
    "previsao.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.552490839548454\n"
     ]
    }
   ],
   "source": [
    "# Criando métrica de avaliação\n",
    "# predictionCol - Coluna que tem as informações da previsão\n",
    "# labelCol - Coluna que possui as informaçoes verdadeiras (é onde está a classe)\n",
    "# metricName - é a métrica que gostariamos de utiliza para avaliar \n",
    "\n",
    "avaliar = RegressionEvaluator(predictionCol='prediction', labelCol='HP', metricName='rmse')\n",
    "\n",
    "# avaliando o dataframe \"previsao\"\n",
    "rmse = avaliar.evaluate(previsao)\n",
    "\n",
    "# verificar o valor retornado, no caso do RMSE quando menor melhor, seria mais ou menos o tanto que ele errou.\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando motelo usando Random Forest Regressor\n",
    "\n",
    "rfreg = RandomForestRegressor(featuresCol='caracteristicas', labelCol='HP')\n",
    "modelo2 = rfreg.fit(carrosTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---+------------------+------------------+\n",
      "|Consumo|Cilindros|Cilindradas| HP|   caracteristicas|        prediction|\n",
      "+-------+---------+-----------+---+------------------+------------------+\n",
      "|     15|        8|        301|335|  [15.0,8.0,301.0]|205.55337301587306|\n",
      "|    104|        8|        472|205| [104.0,8.0,472.0]|194.26289682539684|\n",
      "|    133|        8|        350|245| [133.0,8.0,350.0]|  228.623373015873|\n",
      "|    155|        8|        318|150| [155.0,8.0,318.0]|205.81587301587305|\n",
      "|    164|        8|       2758|180|[164.0,8.0,2758.0]| 180.0575396825397|\n",
      "+-------+---------+-----------+---+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previsao2 = modelo2.transform(CarrosTeste)\n",
    "previsao2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.552490839548454\n",
      "44.98310569434564\n"
     ]
    }
   ],
   "source": [
    "# comparando cada tecnica de modelo\n",
    "\n",
    "rmse = avaliar.evaluate(previsao)\n",
    "rmse2 = avaliar.evaluate(previsao2)\n",
    "\n",
    "print(rmse)\n",
    "print(rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 59. Preparando Dados para Classificação (Classificação de churn binária)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "churn = spark.read.csv(r\"C:\\Users\\viser\\OneDrive\\Documentos\\Cursos\\UDEMY_Formação Spark com pySpark\\Material\\files\\Churn.csv\", inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+-----+\n",
      "|features                                                        |label|\n",
      "+----------------------------------------------------------------+-----+\n",
      "|[619.0,1.0,0.0,0.0,42.0,2.0,0.0,1.0,1.0,1.0,1.0134888E7]        |1.0  |\n",
      "|[608.0,0.0,0.0,0.0,41.0,1.0,8380786.0,1.0,0.0,1.0,1.1254258E7]  |0.0  |\n",
      "|[502.0,1.0,0.0,0.0,42.0,8.0,1596608.0,3.0,1.0,0.0,1.1393157E7]  |1.0  |\n",
      "|(11,[0,1,4,5,7,10],[699.0,1.0,39.0,1.0,2.0,9382663.0])          |0.0  |\n",
      "|[850.0,0.0,0.0,0.0,43.0,2.0,1.2551082E7,1.0,1.0,1.0,790841.0]   |0.0  |\n",
      "|[645.0,0.0,0.0,1.0,44.0,8.0,1.1375578E7,2.0,1.0,0.0,1.4975671E7]|1.0  |\n",
      "|[822.0,1.0,0.0,1.0,50.0,7.0,0.0,2.0,1.0,1.0,100628.0]           |0.0  |\n",
      "|[376.0,0.0,1.0,0.0,29.0,4.0,1.1504674E7,4.0,1.0,0.0,1.1934688E7]|1.0  |\n",
      "|[501.0,1.0,0.0,1.0,44.0,4.0,1.4205107E7,2.0,0.0,1.0,749405.0]   |0.0  |\n",
      "|[684.0,1.0,0.0,1.0,27.0,2.0,1.3460388E7,1.0,1.0,1.0,7172573.0]  |0.0  |\n",
      "|[528.0,1.0,0.0,1.0,31.0,6.0,1.0201672E7,2.0,0.0,0.0,8018112.0]  |0.0  |\n",
      "|[497.0,0.0,0.0,1.0,24.0,3.0,0.0,2.0,1.0,0.0,7639001.0]          |0.0  |\n",
      "|[476.0,1.0,0.0,0.0,34.0,10.0,0.0,2.0,1.0,0.0,2626098.0]         |0.0  |\n",
      "|(11,[0,1,4,5,7,10],[549.0,1.0,25.0,5.0,2.0,1.9085779E7])        |0.0  |\n",
      "|[635.0,0.0,0.0,0.0,35.0,7.0,0.0,2.0,1.0,1.0,6595165.0]          |0.0  |\n",
      "|[616.0,0.0,1.0,1.0,45.0,3.0,1.4312941E7,2.0,0.0,1.0,6432726.0]  |0.0  |\n",
      "|[653.0,0.0,1.0,1.0,58.0,1.0,1.3260288E7,1.0,1.0,0.0,509767.0]   |1.0  |\n",
      "|[549.0,0.0,0.0,0.0,24.0,9.0,0.0,2.0,1.0,1.0,1440641.0]          |0.0  |\n",
      "|(11,[0,3,4,5,7,10],[587.0,1.0,45.0,6.0,1.0,1.5868481E7])        |0.0  |\n",
      "|[726.0,1.0,0.0,0.0,24.0,6.0,0.0,2.0,1.0,1.0,5472403.0]          |0.0  |\n",
      "+----------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RFormula faz vários tipos de transformações\n",
    "\n",
    "formula = RFormula(formula=\"Exited ~ .\", featuresCol=\"features\", labelCol=\"label\", handleInvalid=\"skip\")\n",
    "churn_trans = formula.fit(churn).transform(churn).select('features', 'label')\n",
    "\n",
    "churn_trans.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60. Criando um Modelo de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7067\n",
      "2933\n"
     ]
    }
   ],
   "source": [
    "churnTreino, churnTeste = churn_trans.randomSplit([0.7,0.3])\n",
    "print(churnTreino.count())\n",
    "print(churnTeste.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='label', featuresCol='features')\n",
    "modelo = dt.fit(churnTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+--------------------+----------+\n",
      "|            features|label| rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------+--------------------+----------+\n",
      "|(11,[0,1,4,5,7,10...|  1.0|  [34.0,240.0]|[0.12408759124087...|       1.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  1.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|  [173.0,36.0]|[0.82775119617224...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  1.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  1.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "|(11,[0,1,4,5,7,10...|  0.0|[4399.0,495.0]|[0.89885574172456...|       0.0|\n",
      "+--------------------+-----+--------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previsao_class = modelo.transform(churnTeste)\n",
    "previsao_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7124250714372676\n"
     ]
    }
   ],
   "source": [
    "avaliar = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "areaUnderROC = avaliar.evaluate(previsao_class)\n",
    "\n",
    "print(areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 61. Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|        160|             39|2875| 1702|        0|          1|      4|          4|110|\n",
      "|    228|        4|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        6|        258|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        8|        360|            315| 344| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "carros_tmp = spark.read.csv(r\"C:\\Users\\viser\\OneDrive\\Documentos\\Cursos\\UDEMY_Formação Spark com pySpark\\Material\\files\\Carros.csv\", inferSchema=True, header=True, sep=';')\n",
    "carros_tmp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas| HP|\n",
      "+-------+---------+-----------+---+\n",
      "|     21|        6|        160|110|\n",
      "|     21|        6|        160|110|\n",
      "|    228|        4|        108| 93|\n",
      "|    214|        6|        258|110|\n",
      "|    187|        8|        360|175|\n",
      "+-------+---------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carros = carros_tmp.select(\"Consumo\",\"Cilindros\",\"Cilindradas\",\"HP\")\n",
    "carros.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividifrom r em treino e teste\n",
    "carrosTreino, carrosTeste = carros.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar vetor de caracteristicas\n",
    "veccaracteristicas = VectorAssembler(inputCols=[(\"Consumo\"),(\"Cilindros\"),(\"Cilindradas\")],outputCol=\"caracteristicas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---+-----------------+\n",
      "|Consumo|Cilindros|Cilindradas| HP|  caracteristicas|\n",
      "+-------+---------+-----------+---+-----------------+\n",
      "|     15|        8|        301|335| [15.0,8.0,301.0]|\n",
      "|     21|        6|        160|110| [21.0,6.0,160.0]|\n",
      "|     21|        6|        160|110| [21.0,6.0,160.0]|\n",
      "|    104|        8|        472|205|[104.0,8.0,472.0]|\n",
      "|    133|        8|        350|245|[133.0,8.0,350.0]|\n",
      "+-------+---------+-----------+---+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#aplicamos em dados de treino\n",
    "vec_carrosTreino = veccaracteristicas.transform(carrosTreino)\n",
    "vec_carrosTreino.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criamos modelo \n",
    "#coluna caracteristicas foi criaada pelo VectorAssembler\n",
    "reglin = LinearRegression(featuresCol=\"caracteristicas\", labelCol=\"HP\")\n",
    "modelo = reglin.fit(vec_carrosTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---+-----------------+------------------+\n",
      "|Consumo|Cilindros|Cilindradas| HP|  caracteristicas|        prediction|\n",
      "+-------+---------+-----------+---+-----------------+------------------+\n",
      "|     21|        6|        160|110| [21.0,6.0,160.0]|162.32154816816646|\n",
      "|     21|        6|        160|110| [21.0,6.0,160.0]|162.32154816816646|\n",
      "|    228|        4|        108| 93|[228.0,4.0,108.0]| 82.51715587712931|\n",
      "|    214|        6|        258|110|[214.0,6.0,258.0]|141.86680518718754|\n",
      "|    187|        8|        360|175|[187.0,8.0,360.0]|202.93528239714834|\n",
      "+-------+---------+-----------+---+-----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pipelines permite criar um fluxo do processo\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[veccaracteristicas,reglin])\n",
    "#fit \n",
    "pipelineModel = pipeline.fit(carros)\n",
    "#previsão\n",
    "previsao = pipelineModel.transform(carros)\n",
    "previsao.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 61. Ativididades: Faça você mesmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|      class|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "iris = spark.read.csv(r\"C:\\Users\\viser\\OneDrive\\Documentos\\Cursos\\UDEMY_Formação Spark com pySpark\\Material\\files\\iris.csv\", inferSchema=True, header=True)\n",
    "iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|features         |label|\n",
      "+-----------------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|0.0  |\n",
      "|[4.9,3.0,1.4,0.2]|0.0  |\n",
      "|[4.7,3.2,1.3,0.2]|0.0  |\n",
      "|[4.6,3.1,1.5,0.2]|0.0  |\n",
      "|[5.0,3.6,1.4,0.2]|0.0  |\n",
      "|[5.4,3.9,1.7,0.4]|0.0  |\n",
      "|[4.6,3.4,1.4,0.3]|0.0  |\n",
      "|[5.0,3.4,1.5,0.2]|0.0  |\n",
      "|[4.4,2.9,1.4,0.2]|0.0  |\n",
      "|[4.9,3.1,1.5,0.1]|0.0  |\n",
      "|[5.4,3.7,1.5,0.2]|0.0  |\n",
      "|[4.8,3.4,1.6,0.2]|0.0  |\n",
      "|[4.8,3.0,1.4,0.1]|0.0  |\n",
      "|[4.3,3.0,1.1,0.1]|0.0  |\n",
      "|[5.8,4.0,1.2,0.2]|0.0  |\n",
      "|[5.7,4.4,1.5,0.4]|0.0  |\n",
      "|[5.4,3.9,1.3,0.4]|0.0  |\n",
      "|[5.1,3.5,1.4,0.3]|0.0  |\n",
      "|[5.7,3.8,1.7,0.3]|0.0  |\n",
      "|[5.1,3.8,1.5,0.3]|0.0  |\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RFormula faz vários tipos de transformações\n",
    "\n",
    "formula = RFormula(formula=\"class ~ .\", featuresCol=\"features\", labelCol=\"label\", handleInvalid=\"skip\")\n",
    "iris = formula.fit(iris).transform(iris).select('features', 'label')\n",
    "\n",
    "iris.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "irisTreino, irisTeste = iris.randomSplit([0.7,0.3])\n",
    "print(irisTreino.count())\n",
    "print(irisTeste.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(smoothing=2, labelCol='label', featuresCol='features')\n",
    "modelo = dt.fit(irisTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|         features|label|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|[4.4,3.2,1.3,0.2]|  0.0|[-10.864765395492...|[0.72573874227767...|       0.0|\n",
      "|[4.6,3.1,1.5,0.2]|  0.0|[-11.283272490601...|[0.69127358832488...|       0.0|\n",
      "|[4.8,3.0,1.4,0.1]|  0.0|[-10.764991932204...|[0.72969422887009...|       0.0|\n",
      "|[4.8,3.4,1.9,0.2]|  0.0|[-12.522385166056...|[0.67360448122995...|       0.0|\n",
      "|[4.9,2.4,3.3,1.0]|  1.0|[-17.074385273706...|[0.12450791427337...|       1.0|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previsao_iris = modelo.transform(irisTeste)\n",
    "previsao_iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "avaliar_iris = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "avaliar_iris = avaliar_iris.evaluate(previsao_iris)\n",
    "\n",
    "## esse modelo mostra 92 de certo\n",
    "print(avaliar_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 62. Solução Faça você mesmo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
